{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09_intrinsic-calibration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOu+U8GKTkvaPXlx06hn+mQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m0tchy/camera-geometry-tutorial/blob/main/09_intrinsic_calibration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmbVuPT02d5M"
      },
      "source": [
        "# 内部パラメーター（カメラ行列）\n",
        "\n",
        "https://docs.opencv.org/4.5.0/d9/d0c/group__calib3d.html#details\n",
        "\n",
        "これまで説明した通り、カメラは姿勢を表す $R$, $\\boldsymbol{T}$ によって世界座標の点をカメラ座標に変換します。\n",
        "$$ \n",
        "\\boldsymbol{X}^\\mathsf{C} = R X^\\mathsf{W} + \\boldsymbol{T}\n",
        "$$\n",
        "同次座標では、\n",
        "$$\n",
        "\\tilde{\\boldsymbol{X}}^\\mathsf{C} = \\begin{bmatrix} R & \\boldsymbol{T} \\\\ 0^\\top & 1 \\end{bmatrix} \\tilde{\\boldsymbol{X}}^\\mathsf{W} \n",
        "$$\n",
        "そして、それを透視投影して、投影面 $Z = f$ 上の点に映します。\n",
        "$$\n",
        "\\tilde{\\boldsymbol{X}}'^\\mathsf{C}  = \\begin{bmatrix} \n",
        "    f & 0 & 0 & 0 \\\\ \n",
        "    0 & f & 0 & 0 \\\\ \n",
        "    0 & 0 & f & 0 \\\\ \n",
        "    0 & 0 & 1 & 0 \\end{bmatrix} \\tilde{\\boldsymbol{X}}^\\mathsf{C} \n",
        "$$\n",
        "この計算結果の X, Y 座標だけを使って2次元の図形と考えたものがカメラ画像です。\n",
        "そこで、Z を最初から計算しないようにするとこうなります。\n",
        "$$\n",
        "\\tilde{\\boldsymbol{x}}  = \\begin{bmatrix} \n",
        "    f & 0 & 0 & 0 \\\\ \n",
        "    0 & f & 0 & 0 \\\\ \n",
        "    0 & 0 & 1 & 0 \\end{bmatrix} \\tilde{\\boldsymbol{X}}^\\mathsf{C} \n",
        "$$\n",
        "左辺を $\\tilde{\\boldsymbol{x}}$ に変えました。これは2次元平面の同次座標です。\n",
        "ここで、 $f$ はカメラの特性を表すものですが、以下のように、 Z 成分を無視するという計算と分けることができます。\n",
        "\n",
        "\\begin{align}\n",
        "\\tilde{\\boldsymbol{x}}  &= \n",
        "\\begin{bmatrix} \n",
        "    f & 0 & 0  \\\\ \n",
        "    0 & f & 0  \\\\ \n",
        "    0 & 0 & 1  \\end{bmatrix}\n",
        "\\begin{bmatrix} \n",
        "    1 & 0 & 0 & 0 \\\\ \n",
        "    0 & 1 & 0 & 0 \\\\ \n",
        "    0 & 0 & 1 & 0 \\end{bmatrix} \n",
        "\\tilde{\\boldsymbol{X}}^\\mathsf{C} \\\\\n",
        "&=\n",
        "\\begin{bmatrix} \n",
        "    f & 0 & 0  \\\\ \n",
        "    0 & f & 0  \\\\ \n",
        "    0 & 0 & 1  \\end{bmatrix} \n",
        "\\begin{bmatrix} I \\mid 0 \\end{bmatrix} \n",
        "\\tilde{\\boldsymbol{X}}^\\mathsf{C} \n",
        "\\end{align}\n",
        "\n",
        "カメラの姿勢の計算まで合わせると、\n",
        "\\begin{align}\n",
        "\\tilde{\\boldsymbol{x}}  &= \n",
        "\\begin{bmatrix} \n",
        "    f & 0 & 0  \\\\ \n",
        "    0 & f & 0  \\\\ \n",
        "    0 & 0 & 1  \\end{bmatrix}\n",
        "\\begin{bmatrix} I \\mid 0 \\end{bmatrix} \n",
        "\\begin{bmatrix} R & \\boldsymbol{T} \\\\ 0^\\top & 1 \\end{bmatrix}\\tilde{\\boldsymbol{X}}^\\mathsf{W} \\\\\n",
        "&=\n",
        "\\begin{bmatrix} \n",
        "    f & 0 & 0  \\\\ \n",
        "    0 & f & 0  \\\\ \n",
        "    0 & 0 & 1  \\end{bmatrix}\n",
        "\\begin{bmatrix} R \\mid \\boldsymbol{T} \\end{bmatrix} \n",
        "\\tilde{\\boldsymbol{X}}^\\mathsf{W}\n",
        "\\end{align}\n",
        "というように、シンプルになります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX7Znyh27Ys1"
      },
      "source": [
        "さて、3次元の点を計測したとき、最終的には画像上の点に対応しますが、\n",
        "画像の座標はふつう左上が原点です。また、\n",
        "カメラの投影中心がちょうど画像の真ん中であるとは限りません。\n",
        "さらに言えば、カメラの光軸に対して [CCD](https://ja.wikipedia.org/wiki/CCD%E3%82%A4%E3%83%A1%E3%83%BC%E3%82%B8%E3%82%BB%E3%83%B3%E3%82%B5) が正確に垂直に置かれているとも限らず、その傾きによって画像は変形するでしょう。\n",
        "\n",
        "正規化されたカメラ画像から画素に対する画像座標へ直接変換をするために、線形変換（アフィン変換）で書ける部分と、それ以外の非線形な変換 $g$ に分けることを考えます。\n",
        "\n",
        "\\begin{align}\n",
        "\\tilde{\\boldsymbol{x}}  &= g\\left( \n",
        "\\begin{bmatrix} \n",
        "    f_x & s & c_x  \\\\ \n",
        "    0 & f_y & c_y  \\\\ \n",
        "    0 & 0 & 1  \\end{bmatrix}\n",
        "\\begin{bmatrix} \n",
        "    1 & 0 & 0 & 0 \\\\ \n",
        "    0 & 1 & 0 & 0 \\\\ \n",
        "    0 & 0 & 1 & 0 \\end{bmatrix} \n",
        "\\tilde{\\boldsymbol{X}}^\\mathsf{C} \\right) \\\\\n",
        "&= g\\left(A \\left[ R \\mid \\boldsymbol{T} \\right] \\tilde{\\boldsymbol{X}}^\\mathsf{W} \\right)\n",
        "\\end{align}\n",
        "ここで、 $f_x$, $f_y$ は焦点距離が歪みによって x, y 方向に少しずれがある可能性を考慮しています。\n",
        "また、カメラ座標では光軸が (0, 0) を通りますが、これが画像のどこになるかを表す平行移動成分 $c_x, c_y$ があり、\n",
        "また $s$ はせん断係数です。\n",
        "これらを**カメラの内部パラメーター** (intrinsic parameters) といい、\n",
        "一般にこのような上三角行列を内部行列とかカメラ行列といいます。\n",
        "\n",
        "そして、このカメラ固有の情報を計測することをカメラの（内部）**キャリブレーション** (calibration; 校正) といいます。\n",
        "\n",
        "非線形な歪みを表す $g$ は、 radial distortion と tangential distortion によってモデル化することができますが詳細は省略します。\n",
        "あらかじめ画像の歪みを補正することで、それ以降の計算では気にする必要がなくなります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71_9lSElft3H"
      },
      "source": [
        "# 内部パラメーターのキャリブレーション（内部校正）\n",
        "\n",
        "[OpenCV のチュートリアル](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_calibration/py_calibration.html) を参考にしていますが、 Colab でできるように改変しています。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHle2oiuH3Eg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBE8j6gQU6V7"
      },
      "source": [
        "まず、キャリブレーションに使う画像を撮影しアップロードします。\n",
        "資料フォルダにある `Calibration Chess Board(A4).pdf` をパソコンなどで表示し、フルスクリーンにします (Acrobat Reader の Windows 版では Ctrl-L)。\n",
        "\n",
        "その画面を、いろんな距離、いろんな角度で撮影します。\n",
        "20枚以上はとってください。\n",
        "\n",
        "それを適当なフォルダにアップロードします。\n",
        "左の「フォルダ」アイコンをクリックして、ファイルの画面にします。\n",
        "開いているところを右クリックして「新しいフォルダ」を作り、その中に撮った画像をアップロードしてください。\n",
        "\n",
        "以下のコードで、そのフォルダを指定すると、ファイルがリストアップされるはずです。\n",
        "なお、このアップロードしたファイルは Google Colab が切断されると消えてしまうので、やり直すときは再度アップロードする必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGxC76gCMERD"
      },
      "source": [
        "images_dir = \"images\"\n",
        "fn_images = os.listdir(images_dir)\n",
        "fn_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag-3__DodRCW"
      },
      "source": [
        "うまく取得できたら、画像を読み込んでリストにします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBjYIcPGMmUj"
      },
      "source": [
        "images = []\n",
        "\n",
        "for fn in fn_images:\n",
        "    images.append(cv2.imread(images_dir + \"/\" + fn))\n",
        "    print(fn, images[0].shape)\n",
        "\n",
        "# 1つのカメラのキャリブレーションなので、\n",
        "# 画像サイズは全部同じであるはず\n",
        "# numpy.ndarray では (高さ, 幅, チャンネル) の順なので、\n",
        "# OpenCV の関数用に入れ替える\n",
        "image_size = images[0].shape[1::-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JacjuoGZdz8x"
      },
      "source": [
        "チェスボードの交点を検出する準備をします。\n",
        "* 今回は、マス目が 8x6 になっているので、交点は 7x5 です。\n",
        "* パターンの世界座標を用意します。\n",
        "* 検出の基準を決めます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yClXi0Rfhg6z"
      },
      "source": [
        "corner_size = (7, 5)\n",
        "\n",
        "# チェスボードの交点の世界座標\n",
        "# チェスボードを Z = 0 平面と考え、\n",
        "# (0, 0, 0) から (7-1, 5-1, 0)\n",
        "object_points = np.mgrid[0:corner_size[0], 0:corner_size[1], 0:1].T.reshape(-1, 3).astype(np.float32)\n",
        "object_points.shape\n",
        "\n",
        "# 検出のための基準を決める（詳細は最初はわからなくても可）\n",
        "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHzDjVd7hmtZ"
      },
      "source": [
        "コーナーの検出をします。必ずしも成功するとは限りません。また、それなり時間がかかります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P73mzvAmNzHS"
      },
      "source": [
        "%%time\n",
        "\n",
        "detected = []  # 検出が成功した画像の番号\n",
        "detected_corners = []  # 検出した結果\n",
        "object_list = []  # 対応するパターン\n",
        "\n",
        "for i, img in enumerate(images):\n",
        "\n",
        "    # 検出のためにグレースケールに変換する\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    #plt.imshow(img_gray, cmap=\"gray\")\n",
        "\n",
        "    ret, corners = cv2.findChessboardCorners(img_gray, corner_size, None)\n",
        "    #ret, corners.shape\n",
        "\n",
        "    # 失敗したらスキップ\n",
        "    if ret != True:\n",
        "        print(f\"failed for the image {i}\")\n",
        "        continue\n",
        "    \n",
        "    # 検出の精度を高める\n",
        "    corners = cv2.cornerSubPix(img_gray, corners, (11,11), (-1,-1), criteria)\n",
        "\n",
        "    # 結果の保存\n",
        "    detected.append(i)\n",
        "    detected_corners.append(corners)\n",
        "    object_list.append(object_points)\n",
        "\n",
        "    # 結果の表示\n",
        "    # plt.figure()\n",
        "    # plt.imshow(img[:,:,[2,1,0]])\n",
        "    # plt.scatter(corners[:,0,0], corners[:,0,1], color=\"RED\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfqE0FYYqYFo"
      },
      "source": [
        "キャリブレーションの関数はいくつかあるが、一番基本的な Zhang の方法を使う場合。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYXiU7Egg3H7"
      },
      "source": [
        "reproj_error, camera_matrix, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
        "    objectPoints=object_list,  # 各パターンはすべて同じなので、その回数分リピートする\n",
        "    imagePoints=detected_corners, \n",
        "    imageSize=image_size,\n",
        "    cameraMatrix=None,  # 内部パラメーターの初期値は無し\n",
        "    distCoeffs=None  # 歪み係数の初期値は無し\n",
        ")\n",
        "\n",
        "print(f\"RMS reprojection error: {reproj_error}\")\n",
        "print(\"intrinsic matrix:\")\n",
        "print(camera_matrix)\n",
        "print(f\"ditortions: {dist}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyMGpsjd1VoW"
      },
      "source": [
        "座標軸を表示。\n",
        "チェスボードからの相対的なカメラの姿勢を求めることができ、逆に考えるとカメラから見たチェスボードの座標系を知ったということになるので、\n",
        "座標軸を計算して表示できます。\n",
        "\n",
        "本当は歪み補正をしたほうがいいのですが、それは自分でやってみてください。上のURLに説明が書かれています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svRK_nlIkoJ_"
      },
      "source": [
        "for i in range(len(detected)):\n",
        "    img_copy = images[detected[i]].copy()\n",
        "    cv2.drawFrameAxes(img_copy, camera_matrix, dist, rvecs[i], tvecs[i], 10, 30)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(img_copy[:,:,[2,1,0]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_6qawsYCkS-"
      },
      "source": [
        "## note\n",
        "\n",
        "* 求まった $f_x$, $f_y$ の単位は pixel です。もし、物理的な長さにしたい場合は、 CCD の1画素の大きさを掛けることで求まります。例えば、カメラの EXIF には焦点距離が mm で記録されていますが、この値になるはずです。CCD のサイズはカメラの仕様などに載っています。\n",
        "* `rvec` は回転ベクトルと呼ばれるもので、回転軸の単位方向ベクトル $n$ にその回転角度を掛けたものです。つまり、長さが回転角度になっています。\n",
        "* 上のコードでは、 `object_points` として、 (0, 1, 0) のような整数座標を与えていました。この場合、世界の物理的な単位は不明です。もし、整数の代わりに画面上のマス目の長さを使えば、 `rvec`, `tvec` は、その長さの単位に関するものに変わります。ただし、内部パラメーターを計算するのが目的の場合は世界の単位は特に関係ありません。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO9xDNgiw2ex"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yztyBeHxco9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
